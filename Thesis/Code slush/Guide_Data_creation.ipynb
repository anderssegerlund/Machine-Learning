{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d231b906",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab500b8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import edec.afterprocessing as ap\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a68b2",
   "metadata": {},
   "source": [
    "# Different examles how data can be created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08da29",
   "metadata": {},
   "source": [
    "### 1. Data creation for ANN \n",
    "This function return a data set of: \n",
    "- n random tin numbers with label 0 \n",
    "- m random tin numbers with label 1  \n",
    "- Rolling, sample and drop can be set in parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2742b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db = \"df.db\"\n",
    "# Annotate data if needed\n",
    "# ap.annotate_db(fail_type=\"SOC\", db=current_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Paramater values:\n",
    "\n",
    "Sub_sample: How mmany timesamples backwards should be included (0 only give 1 sample, i.e [1,108])\n",
    "drop_sample: How many samples should be dropped (0 for no drop). DROP SAMPLE MUST BE LARGER THAN ROLL\n",
    "roll: How many timesteps back should we roll (1 for no rolling) \n",
    "\"\"\"\n",
    "parameters = {\"nRandom samples\": {\n",
    "                                0: 20,\n",
    "                                1: 20,\n",
    "                                },\n",
    "              \"Sub sample\": 5,\n",
    "              \"drop_sample\": 0,  # Default 0\n",
    "              \"roll\": 1          # Default 1 (Must be larger or equal to subsample)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ap.create_dataset(db=\"df.db\", parameters=parameters,\n",
    "                            normalize_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e42311",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*0.8)\n",
    "test_size = len(data) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(data,[train_size, test_size])\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size,\n",
    "                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011456d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = parameters[\"Sub sample\"]\n",
    "subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3f765",
   "metadata": {},
   "source": [
    "### Test of model data in ANN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef4298",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class ANNMultilayerperceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=(subsample*108),output_size=2, layers=[220, 84]):  # 120, 84\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc2b = nn.Linear(layers[1], 500)\n",
    "        self.fc2c = nn.Linear(500, layers[1])\n",
    "        self.fc2d = nn.Linear(layers[1], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc2b(X))\n",
    "        X = F.relu(self.fc2c(X))\n",
    "        X = F.relu(self.fc2d(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return F.log_softmax(X, dim=1) # PGA multiclass classification\n",
    "        #return X\n",
    "model = ANNMultilayerperceptron()\n",
    "\n",
    "for b, (X_train, y_train) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "model(X_train.view(batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69085c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f544104",
   "metadata": {},
   "source": [
    "## 2. ANN samma som ovan men med tin imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../scripts/dataset_split_dict.pickle', 'rb') as handle:\n",
    "    datasplit_dict = pickle.load(handle)\n",
    "tr = datasplit_dict[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_tin = datasplit_dict[\"train\"] # Select all train tin\n",
    "#train_tin = ap.get_subset_traindata(n_failed=44, n_healthy=10)  #Select defined amount\n",
    "#train_tin_fail, train_tin_healthy = ap.get_subset_data(dataset=\"train\", n_healthy=44, n_failed=44, separate=True)\n",
    "train_tin = ap.get_subset_data(dataset=\"train\", n_healthy=44, n_failed=44, separate=False)\n",
    "\n",
    "\n",
    "validation_tin = datasplit_dict[\"validation\"]\n",
    "test_tin = datasplit_dict[\"test\"]\n",
    "test_final_tin = datasplit_dict[\"test_final\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26336ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "            \"Sub sample\": 2,\n",
    "            \"drop_sample\": 0,  # Default 0\n",
    "            \"roll\": 1          # Default 1 (Must be smaller or equal to subsample)\n",
    "            }\n",
    "\n",
    "test_parameters = {\n",
    "            \"Sub sample\": 2,\n",
    "            \"drop_sample\": 0,  # Default 0\n",
    "            \"roll\": 1          # Default 1 (Must be smaller or equal to subsample)\n",
    "            }\n",
    "\n",
    "train_set = ap.create_tin_dataset(db=\"df.db\", parameters=train_parameters, normalize_data=True,\n",
    "                   show_rundetails=False, tin_list=train_tin)\n",
    "\n",
    "test_set = ap.create_tin_dataset(db=\"df.db\", parameters=test_parameters, normalize_data=True,\n",
    "                   show_rundetails=False, tin_list=test_tin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b95c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = train_parameters[\"Sub sample\"]\n",
    "subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd34428",
   "metadata": {},
   "source": [
    "### Test of model data in ANN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5398def",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class ANNMultilayerperceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=(subsample*108),output_size=2, layers=[220,84]):  # 120, 84\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc2b = nn.Linear(layers[1], 500)\n",
    "        self.fc2c = nn.Linear(500, layers[1])\n",
    "        self.fc2d = nn.Linear(layers[1], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc2b(X))\n",
    "        X = F.relu(self.fc2c(X))\n",
    "        X = F.relu(self.fc2d(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return F.log_softmax(X,dim=1) # PGA multiclass classification\n",
    "        #return X\n",
    "model = ANNMultilayerperceptron()\n",
    "\n",
    "for b, (X_train, y_train) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "model(X_train.view(batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73aa8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c2725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194f829",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
